{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx as onnx\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex Vogt\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "training_data = torchvision.datasets.MNIST(\n",
    "    '/files/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                              torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    "                                             )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a7079efde0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader = DataLoader(training_data, 64, shuffle=True)\n",
    "epochs = 3\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "batch_size = 64\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "linear_relu_stack.0.weight \t torch.Size([512, 784])\n",
      "linear_relu_stack.0.bias \t torch.Size([512])\n",
      "linear_relu_stack.2.weight \t torch.Size([512, 512])\n",
      "linear_relu_stack.2.bias \t torch.Size([512])\n",
      "linear_relu_stack.4.weight \t torch.Size([10, 512])\n",
      "linear_relu_stack.4.bias \t torch.Size([10])\n",
      "Optimizer's state_dict:\n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [0, 1, 2, 3, 4, 5]}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (data, target) in enumerate(train_dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(data)\n",
    "        loss = loss_fn(pred, target)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(data)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.349210  [    0/60000]\n",
      "loss: 1.909350  [ 6400/60000]\n",
      "loss: 1.123892  [12800/60000]\n",
      "loss: 0.687302  [19200/60000]\n",
      "loss: 0.468531  [25600/60000]\n",
      "loss: 0.470848  [32000/60000]\n",
      "loss: 0.452021  [38400/60000]\n",
      "loss: 0.457846  [44800/60000]\n",
      "loss: 0.526327  [51200/60000]\n",
      "loss: 0.425250  [57600/60000]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.233128  [    0/60000]\n",
      "loss: 0.236356  [ 6400/60000]\n",
      "loss: 0.312516  [12800/60000]\n",
      "loss: 0.370720  [19200/60000]\n",
      "loss: 0.261536  [25600/60000]\n",
      "loss: 0.433929  [32000/60000]\n",
      "loss: 0.413369  [38400/60000]\n",
      "loss: 0.379716  [44800/60000]\n",
      "loss: 0.179866  [51200/60000]\n",
      "loss: 0.208052  [57600/60000]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.290081  [    0/60000]\n",
      "loss: 0.215108  [ 6400/60000]\n",
      "loss: 0.383265  [12800/60000]\n",
      "loss: 0.229047  [19200/60000]\n",
      "loss: 0.166082  [25600/60000]\n",
      "loss: 0.265015  [32000/60000]\n",
      "loss: 0.164164  [38400/60000]\n",
      "loss: 0.217300  [44800/60000]\n",
      "loss: 0.286389  [51200/60000]\n",
      "loss: 0.277213  [57600/60000]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7495678a5423b614518f1e7d37edbca4a8c36210f7349cfc3d660176cd54b7f2"
  },
  "kernelspec": {
   "display_name": "Python 3.6.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
